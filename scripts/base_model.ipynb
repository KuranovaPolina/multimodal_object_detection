{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-06T22:21:54.486708Z",
     "iopub.status.busy": "2025-12-06T22:21:54.486383Z",
     "iopub.status.idle": "2025-12-06T22:21:56.297524Z",
     "shell.execute_reply": "2025-12-06T22:21:56.296736Z",
     "shell.execute_reply.started": "2025-12-06T22:21:54.486682Z"
    },
    "id": "zrmPaFFSx3Ru",
    "outputId": "13c8ab84-d3e1-4608-81ca-3503f02c70a0",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "radmilasegen_dataset_path = kagglehub.dataset_download('radmilasegen/dataset')\n",
    "\n",
    "print('Data source import complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:21:56.298571Z",
     "iopub.status.busy": "2025-12-06T22:21:56.298254Z",
     "iopub.status.idle": "2025-12-06T22:21:56.302464Z",
     "shell.execute_reply": "2025-12-06T22:21:56.301675Z",
     "shell.execute_reply.started": "2025-12-06T22:21:56.298551Z"
    },
    "id": "thTd6TOdyDy_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# BASE_PATH = \"/root/.cache/kagglehub/datasets/radmilasegen/dataset/versions/1/new_ds\"\n",
    "BASE_PATH = \"/kaggle/input/dataset/new_ds\"\n",
    "CLASSES_PATH = os.path.join(BASE_PATH, \"merged_classes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:21:56.304372Z",
     "iopub.status.busy": "2025-12-06T22:21:56.303991Z",
     "iopub.status.idle": "2025-12-06T22:22:09.426386Z",
     "shell.execute_reply": "2025-12-06T22:22:09.425849Z",
     "shell.execute_reply.started": "2025-12-06T22:21:56.304349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.427461Z",
     "iopub.status.busy": "2025-12-06T22:22:09.427078Z",
     "iopub.status.idle": "2025-12-06T22:22:09.430884Z",
     "shell.execute_reply": "2025-12-06T22:22:09.430214Z",
     "shell.execute_reply.started": "2025-12-06T22:22:09.427431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.431924Z",
     "iopub.status.busy": "2025-12-06T22:22:09.431644Z",
     "iopub.status.idle": "2025-12-06T22:22:09.450465Z",
     "shell.execute_reply": "2025-12-06T22:22:09.449943Z",
     "shell.execute_reply.started": "2025-12-06T22:22:09.431893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_classes(path=CLASSES_PATH):\n",
    "    with open(path, \"r\") as f:\n",
    "        return [line.strip() for line in f.readlines() if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.451354Z",
     "iopub.status.busy": "2025-12-06T22:22:09.451111Z",
     "iopub.status.idle": "2025-12-06T22:22:09.466696Z",
     "shell.execute_reply": "2025-12-06T22:22:09.466146Z",
     "shell.execute_reply.started": "2025-12-06T22:22:09.451337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_label(label_path):\n",
    "    objects = []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls_id = int(parts[0])\n",
    "            x, y, w, h = map(float, parts[1:])\n",
    "            objects.append({\n",
    "                \"cls_id\": cls_id,\n",
    "                \"class_name\": CLASSES[cls_id],\n",
    "                \"x_center\": x,\n",
    "                \"y_center\": y,\n",
    "                \"width\": w,\n",
    "                \"height\": h\n",
    "            })\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.467393Z",
     "iopub.status.busy": "2025-12-06T22:22:09.467204Z",
     "iopub.status.idle": "2025-12-06T22:22:09.483217Z",
     "shell.execute_reply": "2025-12-06T22:22:09.482725Z",
     "shell.execute_reply.started": "2025-12-06T22:22:09.467378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collect_samples(base_path=BASE_PATH):\n",
    "    samples = []\n",
    "    subfolders = sorted([f for f in os.listdir(base_path) if f.isdigit()])\n",
    "\n",
    "    for folder in subfolders:\n",
    "        img_dir = os.path.join(base_path, folder, \"images\")\n",
    "        depth_dir = os.path.join(base_path, folder, \"depth\")\n",
    "        label_dir = os.path.join(base_path, folder, \"labels\")\n",
    "\n",
    "        if not (os.path.isdir(img_dir) and os.path.isdir(depth_dir) and os.path.isdir(label_dir)):\n",
    "            continue\n",
    "\n",
    "        img_files = sorted(glob(os.path.join(img_dir, \"*.png\")))\n",
    "        \n",
    "        for img_path in img_files:\n",
    "            fname = os.path.basename(img_path)\n",
    "            depth_path = os.path.join(depth_dir, fname)\n",
    "            label_path = os.path.join(label_dir, fname.replace(\".png\", \".txt\"))\n",
    "\n",
    "            if not os.path.exists(depth_path):\n",
    "                continue\n",
    "            if not os.path.exists(label_path):\n",
    "                continue\n",
    "\n",
    "            objs = read_label(label_path)\n",
    "            if len(objs) == 0:\n",
    "                continue\n",
    "\n",
    "            samples.append({\n",
    "                \"rgb\": img_path,\n",
    "                \"depth\": depth_path,\n",
    "                \"label\": label_path,\n",
    "                \"objects\": objs\n",
    "            })\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.484364Z",
     "iopub.status.busy": "2025-12-06T22:22:09.483906Z",
     "iopub.status.idle": "2025-12-06T22:22:09.502273Z",
     "shell.execute_reply": "2025-12-06T22:22:09.501610Z",
     "shell.execute_reply.started": "2025-12-06T22:22:09.484337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_depth_min_max(samples):\n",
    "    d_min = float(\"inf\")\n",
    "    d_max = float(\"-inf\")\n",
    "    for s in samples:\n",
    "        depth = cv2.imread(s[\"depth\"], cv2.IMREAD_ANYDEPTH).astype(np.float32)\n",
    "        if depth.size == 0:\n",
    "            continue\n",
    "        m = depth.min()\n",
    "        M = depth.max()\n",
    "        if M <= 0:\n",
    "            continue\n",
    "        d_min = min(d_min, m)\n",
    "        d_max = max(d_max, M)\n",
    "\n",
    "    if not np.isfinite(d_min):\n",
    "        d_min = 0.0\n",
    "    if not np.isfinite(d_max) or d_max <= d_min:\n",
    "        d_max = d_min + 1.0\n",
    "    return d_min, d_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.504594Z",
     "iopub.status.busy": "2025-12-06T22:22:09.504307Z",
     "iopub.status.idle": "2025-12-06T22:22:09.520674Z",
     "shell.execute_reply": "2025-12-06T22:22:09.519988Z",
     "shell.execute_reply.started": "2025-12-06T22:22:09.504577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RGBDDetectionDataset(Dataset):\n",
    "    def __init__(self, samples, img_size=IMG_SIZE):\n",
    "        self.samples = samples\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "\n",
    "        rgb = cv2.imread(item[\"rgb\"])\n",
    "        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        rgb = cv2.resize(rgb, (self.img_size, self.img_size))\n",
    "        rgb = rgb.astype(np.float32) \n",
    "\n",
    "        depth = cv2.imread(item[\"depth\"], cv2.IMREAD_ANYDEPTH).astype(np.float32)\n",
    "        depth = cv2.resize(depth, (self.img_size, self.img_size))\n",
    "\n",
    "        d = np.clip(depth, DEPTH_MIN, DEPTH_MAX)\n",
    "        d_norm = (d - DEPTH_MIN) / (DEPTH_MAX - DEPTH_MIN + 1e-6)\n",
    "        d_scaled = d_norm * 255.0 \n",
    "\n",
    "        depth_ch = d_scaled[..., None] \n",
    "\n",
    "        rgbd = np.concatenate([rgb, depth_ch], axis=2)\n",
    "        rgbd = rgbd / 255.0\n",
    "        rgbd = torch.from_numpy(rgbd).permute(2, 0, 1)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in item[\"objects\"]:\n",
    "            cx = obj[\"x_center\"]\n",
    "            cy = obj[\"y_center\"]\n",
    "            w  = obj[\"width\"]\n",
    "            h  = obj[\"height\"]\n",
    "\n",
    "            x1 = (cx - w/2.0) * self.img_size\n",
    "            y1 = (cy - h/2.0) * self.img_size\n",
    "            x2 = (cx + w/2.0) * self.img_size\n",
    "            y2 = (cy + h/2.0) * self.img_size\n",
    "\n",
    "            x1 = np.clip(x1, 0, self.img_size-1)\n",
    "            y1 = np.clip(y1, 0, self.img_size-1)\n",
    "            x2 = np.clip(x2, 0, self.img_size-1)\n",
    "            y2 = np.clip(y2, 0, self.img_size-1)\n",
    "\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            labels.append(obj[\"cls_id\"] + 1)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([idx])\n",
    "        }\n",
    "\n",
    "        return rgbd, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.521536Z",
     "iopub.status.busy": "2025-12-06T22:22:09.521308Z",
     "iopub.status.idle": "2025-12-06T22:22:09.541127Z",
     "shell.execute_reply": "2025-12-06T22:22:09.540452Z",
     "shell.execute_reply.started": "2025-12-06T22:22:09.521512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, targets = list(zip(*batch))\n",
    "    return list(images), list(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.542006Z",
     "iopub.status.busy": "2025-12-06T22:22:09.541844Z",
     "iopub.status.idle": "2025-12-06T22:22:09.560310Z",
     "shell.execute_reply": "2025-12-06T22:22:09.559818Z",
     "shell.execute_reply.started": "2025-12-06T22:22:09.541994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_n_predictions(model, samples, n = 5, score_thresh=0.5):\n",
    "    model.eval()\n",
    "    chosen = random.sample(samples, min(5, len(samples)))\n",
    "\n",
    "    for idx, sample in enumerate(chosen):\n",
    "        print(f\"\\n============= SAMPLE {idx+1} =============\")\n",
    "\n",
    "        # читаем RGB/DEPTH так же, как в датасете\n",
    "        rgb = cv2.imread(sample[\"rgb\"])\n",
    "        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        rgb = cv2.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "        rgb_vis = rgb.copy()\n",
    "\n",
    "        depth = cv2.imread(sample[\"depth\"], cv2.IMREAD_ANYDEPTH).astype(np.float32)\n",
    "        depth = cv2.resize(depth, (IMG_SIZE, IMG_SIZE))\n",
    "        d = np.clip(depth, DEPTH_MIN, DEPTH_MAX)\n",
    "        d_norm = (d - DEPTH_MIN) / (DEPTH_MAX - DEPTH_MIN + 1e-6)\n",
    "        d_scaled = d_norm * 255.0\n",
    "        depth_ch = d_scaled[..., None]\n",
    "\n",
    "        rgbd = np.concatenate([rgb.astype(np.float32), depth_ch], axis=2) / 255.0\n",
    "        rgbd_t = torch.from_numpy(rgbd).permute(2, 0, 1).float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model([rgbd_t])[0]\n",
    "\n",
    "        boxes = outputs[\"boxes\"].cpu().numpy()\n",
    "        labels = outputs[\"labels\"].cpu().numpy()\n",
    "        scores = outputs[\"scores\"].cpu().numpy()\n",
    "\n",
    "        for box, label, score in zip(boxes, labels, scores):\n",
    "            if score < score_thresh:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = box.astype(int)\n",
    "            cls_id = int(label) - 1  # back to 0..C-1\n",
    "            if cls_id < 0 or cls_id >= len(CLASSES):\n",
    "                continue\n",
    "            cls_name = CLASSES[cls_id]\n",
    "\n",
    "            cv2.rectangle(rgb_vis, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(\n",
    "                rgb_vis,\n",
    "                f\"{cls_name} {score:.2f}\",\n",
    "                (x1, max(0, y1 - 5)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 0, 0),\n",
    "                1,\n",
    "            )\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title(\"Predictions\")\n",
    "        plt.imshow(rgb_vis)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-12-06T22:22:09.561170Z",
     "iopub.status.busy": "2025-12-06T22:22:09.560999Z"
    },
    "id": "E-eA282JyFj9",
    "outputId": "a2a98bc3-21d5-4208-d8eb-9b5b4a3c1f13",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Классы: ['bottle', 'box', 'cola', 'container', 'cube', 'duck', 'pods', 'scissors', 'sphere', 'tape', 'tor']\n",
      "Всего валидных RGB+Depth+Label пар: 2424\n",
      "Пример sample: {'rgb': '/kaggle/input/dataset/new_ds/1/images/00000.png', 'depth': '/kaggle/input/dataset/new_ds/1/depth/00000.png', 'label': '/kaggle/input/dataset/new_ds/1/labels/00000.txt', 'objects': [{'cls_id': 5, 'class_name': 'duck', 'x_center': 0.5128571428571428, 'y_center': 0.7398941798941798, 'width': 0.11523809523809515, 'height': 0.31153439153439166}]}\n",
      "DEPTH_MIN, DEPTH_MAX: 0.0 65535.0\n",
      "Train size: 1939 Val size: 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Faster R-CNN RGBD создана.\n",
      "Epoch 1/10 | train_loss = 0.4456\n"
     ]
    }
   ],
   "source": [
    "# multimodal detector (Faster R-CNN + ResNet-50 FPN)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "CLASSES = load_classes()\n",
    "num_classes = len(CLASSES)\n",
    "num_classes_with_bg = num_classes + 1\n",
    "print(\"Классы:\", CLASSES)\n",
    "\n",
    "samples = collect_samples()\n",
    "print(\"Всего валидных RGB+Depth+Label пар:\", len(samples))\n",
    "print(\"Пример sample:\", samples[0])\n",
    "\n",
    "DEPTH_MIN, DEPTH_MAX = compute_depth_min_max(samples)\n",
    "print(\"DEPTH_MIN, DEPTH_MAX:\", DEPTH_MIN, DEPTH_MAX)\n",
    "\n",
    "random.shuffle(samples)\n",
    "split = int(0.8 * len(samples))\n",
    "train_samples = samples[:split]\n",
    "val_samples   = samples[split:]\n",
    "\n",
    "train_dataset = RGBDDetectionDataset(train_samples, IMG_SIZE)\n",
    "val_dataset   = RGBDDetectionDataset(val_samples,   IMG_SIZE)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=(device == \"cuda\"),\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=(device == \"cuda\"),\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_dataset), \"Val size:\", len(val_dataset))\n",
    "\n",
    "backbone = resnet_fpn_backbone('resnet50', weights=None, trainable_layers=5)\n",
    "old_conv = backbone.body.conv1\n",
    "\n",
    "backbone.body.conv1 = nn.Conv2d(\n",
    "    in_channels=4,\n",
    "    out_channels=old_conv.out_channels,\n",
    "    kernel_size=old_conv.kernel_size,\n",
    "    stride=old_conv.stride,\n",
    "    padding=old_conv.padding,\n",
    "    bias=(old_conv.bias is not None),\n",
    ")\n",
    "\n",
    "model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=num_classes_with_bg,\n",
    "    # 4 канала → 4 значения mean/std\n",
    "    image_mean=[0.5, 0.5, 0.5, 0.5],\n",
    "    image_std=[0.25, 0.25, 0.25, 0.25],\n",
    ").to(device)\n",
    "\n",
    "print(\"Модель Faster R-CNN RGBD создана.\")\n",
    "\n",
    "EPOCHS = 10\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.001,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = len(images)\n",
    "        total_loss += losses.item() * bs\n",
    "        n_samples += bs\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | train_loss = {total_loss / n_samples:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"rgbd_fasterrcnn_resnet50.pth\")\n",
    "print(\"Модель сохранена: rgbd_fasterrcnn_resnet50.pth\")\n",
    "\n",
    "show_n_predictions(model, samples, n = 5, score_thresh=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчет метрик качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    IoU для двух боксов в формате [x1, y1, x2, y2].\n",
    "    \"\"\"\n",
    "    x1 = max(float(box1[0]), float(box2[0]))\n",
    "    y1 = max(float(box1[1]), float(box2[1]))\n",
    "    x2 = min(float(box1[2]), float(box2[2]))\n",
    "    y2 = min(float(box1[3]), float(box2[3]))\n",
    "\n",
    "    inter_w = max(0.0, x2 - x1)\n",
    "    inter_h = max(0.0, y2 - y1)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    if inter <= 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    area1 = max(0.0, float(box1[2]) - float(box1[0])) * max(0.0, float(box1[3]) - float(box1[1]))\n",
    "    area2 = max(0.0, float(box2[2]) - float(box2[0])) * max(0.0, float(box2[3]) - float(box2[1]))\n",
    "    union = area1 + area2 - inter\n",
    "    if union <= 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    return inter / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_detection(model, data_loader, class_names, device=None,\n",
    "                    iou_thresh=0.5, score_thresh=0.5):\n",
    "    \"\"\"\n",
    "    Простая оценка детектора на data_loader (например, val_loader):\n",
    "\n",
    "    - общий precision / recall / F1\n",
    "    - precision / recall / F1 по классам\n",
    "    - средний IoU по всем true positive матчам\n",
    "\n",
    "    НИЧЕГО не рисует, только print.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    total_gt = 0       # общее число GT-боксов\n",
    "    total_pred = 0     # общее число предсказаний (после порога по score)\n",
    "    total_tp = 0       # общее число true positives\n",
    "\n",
    "    iou_sum = 0.0\n",
    "    iou_cnt = 0\n",
    "\n",
    "    per_class_gt = [0] * num_classes\n",
    "    per_class_pred = [0] * num_classes\n",
    "    per_class_tp = [0] * num_classes\n",
    "    per_class_iou_sum = [0.0] * num_classes\n",
    "    per_class_iou_cnt = [0] * num_classes\n",
    "\n",
    "    for images, targets in data_loader:\n",
    "        # images — список тензоров [4, H, W]\n",
    "        images = [img.to(device) for img in images]\n",
    "\n",
    "        # прогоняем модель в inference-режиме\n",
    "        outputs = model(images)\n",
    "\n",
    "        for out, tgt in zip(outputs, targets):\n",
    "            gt_boxes = tgt[\"boxes\"].cpu().numpy()\n",
    "            gt_labels = tgt[\"labels\"].cpu().numpy()  # 1..num_classes (0 — фон не используется)\n",
    "\n",
    "            # считаем GT\n",
    "            total_gt += len(gt_boxes)\n",
    "            for lbl in gt_labels:\n",
    "                if 1 <= lbl <= num_classes:\n",
    "                    per_class_gt[lbl - 1] += 1\n",
    "\n",
    "            # если GT вообще нет, все предсказания пойдут в FP\n",
    "            if len(gt_boxes) == 0:\n",
    "                pred_scores = out[\"scores\"].cpu().numpy()\n",
    "                pred_labels = out[\"labels\"].cpu().numpy()\n",
    "\n",
    "                keep = pred_scores >= score_thresh\n",
    "                pred_labels = pred_labels[keep]\n",
    "\n",
    "                num_pred = len(pred_labels)\n",
    "                total_pred += num_pred\n",
    "                for lbl in pred_labels:\n",
    "                    if 1 <= lbl <= num_classes:\n",
    "                        per_class_pred[lbl - 1] += 1\n",
    "                continue\n",
    "\n",
    "            pred_boxes = out[\"boxes\"].cpu().numpy()\n",
    "            pred_labels = out[\"labels\"].cpu().numpy()\n",
    "            pred_scores = out[\"scores\"].cpu().numpy()\n",
    "\n",
    "            # фильтр по порогу score\n",
    "            keep = pred_scores >= score_thresh\n",
    "            pred_boxes = pred_boxes[keep]\n",
    "            pred_labels = pred_labels[keep]\n",
    "            pred_scores = pred_scores[keep]\n",
    "\n",
    "            total_pred += len(pred_boxes)\n",
    "            for lbl in pred_labels:\n",
    "                if 1 <= lbl <= num_classes:\n",
    "                    per_class_pred[lbl - 1] += 1\n",
    "\n",
    "            # для каждого GT отметим, сматчен он или нет\n",
    "            matched_gt = np.zeros(len(gt_boxes), dtype=bool)\n",
    "\n",
    "            # жадный матчинг: перебираем предсказания по убыванию score\n",
    "            order = np.argsort(-pred_scores)\n",
    "            for p_idx in order:\n",
    "                p_box = pred_boxes[p_idx]\n",
    "                p_lbl = pred_labels[p_idx]\n",
    "                if not (1 <= p_lbl <= num_classes):\n",
    "                    continue\n",
    "\n",
    "                best_iou = 0.0\n",
    "                best_gt_idx = -1\n",
    "\n",
    "                for g_idx, (g_box, g_lbl) in enumerate(zip(gt_boxes, gt_labels)):\n",
    "                    if matched_gt[g_idx]:\n",
    "                        continue\n",
    "                    if g_lbl != p_lbl:\n",
    "                        continue\n",
    "\n",
    "                    iou = box_iou(p_box, g_box)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_idx = g_idx\n",
    "\n",
    "                if best_gt_idx >= 0 and best_iou >= iou_thresh:\n",
    "                    # true positive\n",
    "                    matched_gt[best_gt_idx] = True\n",
    "                    total_tp += 1\n",
    "\n",
    "                    iou_sum += best_iou\n",
    "                    iou_cnt += 1\n",
    "\n",
    "                    c = p_lbl - 1\n",
    "                    per_class_tp[c] += 1\n",
    "                    per_class_iou_sum[c] += best_iou\n",
    "                    per_class_iou_cnt[c] += 1\n",
    "                else:\n",
    "                    # false positive — уже учтён в total_pred / per_class_pred\n",
    "                    pass\n",
    "\n",
    "    def safe_div(a, b):\n",
    "        return a / b if b > 0 else 0.0\n",
    "\n",
    "    overall_precision = safe_div(total_tp, total_pred)\n",
    "    overall_recall = safe_div(total_tp, total_gt)\n",
    "    overall_f1 = safe_div(2 * overall_precision * overall_recall,\n",
    "                        overall_precision + overall_recall)\n",
    "    overall_iou = safe_div(iou_sum, iou_cnt)\n",
    "\n",
    "    print(\"===== DETECTION METRICS (IoU >= {:.2f}, score >= {:.2f}) =====\".format(\n",
    "        iou_thresh, score_thresh))\n",
    "    print(f\"Всего GT боксов:      {total_gt}\")\n",
    "    print(f\"Всего предсказаний:   {total_pred}\")\n",
    "    print(f\"True positives (TP):  {total_tp}\")\n",
    "    print(f\"Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Recall:    {overall_recall:.4f}\")\n",
    "    print(f\"F1-score:  {overall_f1:.4f}\")\n",
    "    print(f\"Средний IoU по TP: {overall_iou:.4f}\")\n",
    "    print()\n",
    "\n",
    "    print(\"===== МЕТРИКИ ПО КЛАССАМ =====\")\n",
    "    for idx, name in enumerate(class_names):\n",
    "        tp = per_class_tp[idx]\n",
    "        gt = per_class_gt[idx]\n",
    "        pred = per_class_pred[idx]\n",
    "        prec = safe_div(tp, pred)\n",
    "        rec = safe_div(tp, gt)\n",
    "        f1 = safe_div(2 * prec * rec, prec + rec)\n",
    "        avg_iou = safe_div(per_class_iou_sum[idx], per_class_iou_cnt[idx])\n",
    "\n",
    "        print(f\"[{idx+1}] {name}:\")\n",
    "        print(f\"  GT: {gt}, Pred: {pred}, TP: {tp}\")\n",
    "        print(f\"  Precision: {prec:.4f}\")\n",
    "        print(f\"  Recall:    {rec:.4f}\")\n",
    "        print(f\"  F1-score:  {f1:.4f}\")\n",
    "        print(f\"  Avg IoU:   {avg_iou:.4f}\")\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_detection(model, val_loader, CLASSES, device=device, iou_thresh=0.5, score_thresh=0.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14700256,
     "datasetId": 8877392,
     "isSourceIdPinned": false,
     "sourceId": 13930604,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
