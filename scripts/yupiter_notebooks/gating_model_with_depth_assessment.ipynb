{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13930604,"sourceType":"datasetVersion","datasetId":8877392},{"sourceId":14085872,"sourceType":"datasetVersion","datasetId":8968270}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\nradmilasegen_dataset_path = kagglehub.dataset_download('radmilasegen/dataset-fin')\n\nprint('Data source import complete.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.140851Z","iopub.execute_input":"2025-12-10T20:02:50.141570Z","iopub.status.idle":"2025-12-10T20:02:50.419680Z","shell.execute_reply.started":"2025-12-10T20:02:50.141540Z","shell.execute_reply":"2025-12-10T20:02:50.418896Z"}},"outputs":[{"name":"stdout","text":"Data source import complete.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import os\nfrom glob import glob\n\nBASE_PATH = \"/kaggle/input/dataset-fin/new_ds\"\nCLASSES_PATH = os.path.join(BASE_PATH, \"merged_classes.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.421029Z","iopub.execute_input":"2025-12-10T20:02:50.421267Z","iopub.status.idle":"2025-12-10T20:02:50.424954Z","shell.execute_reply.started":"2025-12-10T20:02:50.421238Z","shell.execute_reply":"2025-12-10T20:02:50.424390Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import random\nimport cv2\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt\n\nfrom torchvision.models.resnet import resnet50, ResNet50_Weights\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork, LastLevelMaxPool\nfrom torchvision.ops import MultiScaleRoIAlign","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.425686Z","iopub.execute_input":"2025-12-10T20:02:50.425934Z","iopub.status.idle":"2025-12-10T20:02:50.442106Z","shell.execute_reply.started":"2025-12-10T20:02:50.425908Z","shell.execute_reply":"2025-12-10T20:02:50.441381Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"IMG_SIZE   = 192\nBATCH_SIZE = 4\nEPOCHS     = 40\nLR         = 0.002\n\nBEST_MODEL_PATH = \"/kaggle/working/best_gating_model.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.442804Z","iopub.execute_input":"2025-12-10T20:02:50.443041Z","iopub.status.idle":"2025-12-10T20:02:50.459489Z","shell.execute_reply.started":"2025-12-10T20:02:50.443015Z","shell.execute_reply":"2025-12-10T20:02:50.458699Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def read_label(path):\n    objs = []\n    with open(path) as f:\n        for line in f:\n            parts = line.strip().split()\n            if len(parts) != 5:\n                continue\n            cls, x, y, w, h = map(float, parts)\n            objs.append(dict(\n                cls_id=int(cls),\n                x_center=x,\n                y_center=y,\n                width=w,\n                height=h\n            ))\n    return objs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.461313Z","iopub.execute_input":"2025-12-10T20:02:50.461577Z","iopub.status.idle":"2025-12-10T20:02:50.473711Z","shell.execute_reply.started":"2025-12-10T20:02:50.461562Z","shell.execute_reply":"2025-12-10T20:02:50.473100Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def collect_samples():\n    samples = []\n    folders = sorted([f for f in os.listdir(BASE_PATH) if f.isdigit()])\n\n    for folder in folders:\n        img_dir   = os.path.join(BASE_PATH, folder, \"images\")\n        depth_dir = os.path.join(BASE_PATH, folder, \"depth\")\n        midas_dir = os.path.join(BASE_PATH, folder, \"depth_midas\")\n        label_dir = os.path.join(BASE_PATH, folder, \"labels\")\n\n        if not all(map(os.path.isdir, [img_dir, depth_dir, midas_dir, label_dir])):\n            continue\n\n        for img_path in glob(os.path.join(img_dir, \"*.png\")):\n            name = os.path.basename(img_path)\n\n            dR = os.path.join(depth_dir, name)\n            dM = os.path.join(midas_dir, name)\n            lb = os.path.join(label_dir, name.replace(\".png\", \".txt\"))\n\n            if not all(map(os.path.exists, [dR, dM, lb])):\n                continue\n\n            objs = read_label(lb)\n            if len(objs) == 0:\n                continue\n\n            samples.append(dict(\n                rgb=img_path,\n                depth_real=dR,\n                depth_midas=dM,\n                objects=objs\n            ))\n    return samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.474511Z","iopub.execute_input":"2025-12-10T20:02:50.475040Z","iopub.status.idle":"2025-12-10T20:02:50.489416Z","shell.execute_reply.started":"2025-12-10T20:02:50.475022Z","shell.execute_reply":"2025-12-10T20:02:50.488766Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def compute_global_min_max(samples):\n    d_min, d_max = 1e9, -1e9\n    for s in samples:\n        dR = cv2.imread(s[\"depth_real\"],  cv2.IMREAD_ANYDEPTH)\n        dM = cv2.imread(s[\"depth_midas\"], cv2.IMREAD_ANYDEPTH)\n        if dR is None or dM is None:\n            continue\n        dR = dR.astype(np.float32)\n        dM = dM.astype(np.float32)\n        d_min = min(d_min, dR.min(), dM.min())\n        d_max = max(d_max, dR.max(), dM.max())\n    return d_min, d_max","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.490073Z","iopub.execute_input":"2025-12-10T20:02:50.490291Z","iopub.status.idle":"2025-12-10T20:02:50.505506Z","shell.execute_reply.started":"2025-12-10T20:02:50.490276Z","shell.execute_reply":"2025-12-10T20:02:50.504843Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class RGBRealMiDaSDataset(Dataset):\n    def __init__(self, samples):\n        self.samples = samples\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        item = self.samples[idx]\n\n        rgb = cv2.imread(item[\"rgb\"])\n        dR  = cv2.imread(item[\"depth_real\"],  cv2.IMREAD_ANYDEPTH)\n        dM  = cv2.imread(item[\"depth_midas\"], cv2.IMREAD_ANYDEPTH)\n\n        if rgb is None or dR is None or dM is None:\n            return self.__getitem__((idx + 1) % len(self.samples))\n\n        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n        dR  = dR.astype(np.float32)\n        dM  = dM.astype(np.float32)\n\n        h0, w0 = rgb.shape[:2]\n\n        scale = min(IMG_SIZE / h0, IMG_SIZE / w0)\n        new_w, new_h = int(w0 * scale), int(h0 * scale)\n\n        rgb_rs = cv2.resize(rgb, (new_w, new_h))\n        dR_rs  = cv2.resize(dR,  (new_w, new_h))\n        dM_rs  = cv2.resize(dM,  (new_w, new_h))\n\n        pad_w = IMG_SIZE - new_w\n        pad_h = IMG_SIZE - new_h\n        pad_left = pad_w // 2\n        pad_top  = pad_h // 2\n\n        rgb_pad = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n        dR_pad  = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.float32)\n        dM_pad  = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.float32)\n\n        rgb_pad[pad_top:pad_top+new_h, pad_left:pad_left+new_w] = rgb_rs\n        dR_pad [pad_top:pad_top+new_h, pad_left:pad_left+new_w] = dR_rs\n        dM_pad [pad_top:pad_top+new_h, pad_left:pad_left+new_w] = dM_rs\n\n        rgb_norm = rgb_pad.astype(np.float32) / 255.0\n        dR_norm  = (dR_pad - DEPTH_MIN) / (DEPTH_MAX - DEPTH_MIN + 1e-6)\n        dM_norm  = (dM_pad - DEPTH_MIN) / (DEPTH_MAX - DEPTH_MIN + 1e-6)\n\n        x = np.concatenate(\n            [rgb_norm, dR_norm[..., None], dM_norm[..., None]],\n            axis=2\n        )\n        x = torch.from_numpy(x).permute(2, 0, 1).float()\n\n        boxes  = []\n        labels = []\n\n        for obj in item[\"objects\"]:\n            cx = obj[\"x_center\"] * w0\n            cy = obj[\"y_center\"] * h0\n            bw = obj[\"width\"]  * w0\n            bh = obj[\"height\"] * h0\n\n            x1 = (cx - bw / 2) * scale + pad_left\n            y1 = (cy - bh / 2) * scale + pad_top\n            x2 = (cx + bw / 2) * scale + pad_left\n            y2 = (cy + bh / 2) * scale + pad_top\n\n            boxes.append([x1, y1, x2, y2])\n            labels.append(obj[\"cls_id\"] + 1)\n\n        boxes  = torch.tensor(boxes, dtype=torch.float32)\n        labels = torch.tensor(labels, dtype=torch.int64)\n\n        target = {\n            \"boxes\": boxes,\n            \"labels\": labels,\n            \"image_id\": torch.tensor([idx]),\n        }\n\n        return x, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.506157Z","iopub.execute_input":"2025-12-10T20:02:50.506379Z","iopub.status.idle":"2025-12-10T20:02:50.521442Z","shell.execute_reply.started":"2025-12-10T20:02:50.506356Z","shell.execute_reply":"2025-12-10T20:02:50.520613Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"class ConvStem(nn.Module):\n    def __init__(self, ch):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(ch, 32, 3, 2, 1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, 3, 1, 1),\n            nn.ReLU()\n        )\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.522772Z","iopub.execute_input":"2025-12-10T20:02:50.523121Z","iopub.status.idle":"2025-12-10T20:02:50.539158Z","shell.execute_reply.started":"2025-12-10T20:02:50.523098Z","shell.execute_reply":"2025-12-10T20:02:50.538482Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class CrossModalGating(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.alpha = nn.Parameter(torch.tensor(0.5))\n    def forward(self, A, B):\n        return self.alpha * A + (1.0 - self.alpha) * B","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.539877Z","iopub.execute_input":"2025-12-10T20:02:50.540154Z","iopub.status.idle":"2025-12-10T20:02:50.553223Z","shell.execute_reply.started":"2025-12-10T20:02:50.540128Z","shell.execute_reply":"2025-12-10T20:02:50.552509Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class FiveChannelStem(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.rgb = ConvStem(3)\n        self.r   = ConvStem(1)\n        self.m   = ConvStem(1)\n        self.g1  = CrossModalGating()\n        self.g2  = CrossModalGating()\n\n    def forward(self, x):\n        f_rgb = self.rgb(x[:, :3])\n        f_r   = self.r  (x[:, 3:4])\n        f_m   = self.m  (x[:, 4:5])\n\n        f_rgb_r = self.g1(f_rgb, f_r)\n        f_all   = self.g2(f_rgb_r, f_m)\n        return f_all","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.553889Z","iopub.execute_input":"2025-12-10T20:02:50.554058Z","iopub.status.idle":"2025-12-10T20:02:50.566807Z","shell.execute_reply.started":"2025-12-10T20:02:50.554045Z","shell.execute_reply":"2025-12-10T20:02:50.566203Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"class RGBRM_Backbone(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.stem = FiveChannelStem()\n        self.body = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n        self.body.conv1 = nn.Conv2d(64, 64, 7, 2, 3, bias=False)\n\n        for name, p in self.body.named_parameters():\n            if \"layer3\" not in name and \"layer4\" not in name:\n                p.requires_grad = False\n\n        self.fpn = FeaturePyramidNetwork(\n            [256, 512, 1024, 2048],\n            256,\n            extra_blocks=LastLevelMaxPool()\n        )\n        self.out_channels = 256\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.body.conv1(x)\n        x = self.body.bn1(x)\n        x = self.body.relu(x)\n        x = self.body.maxpool(x)\n\n        c2 = self.body.layer1(x)\n        c3 = self.body.layer2(c2)\n        c4 = self.body.layer3(c3)\n        c5 = self.body.layer4(c4)\n\n        feats = self.fpn({\"0\": c2, \"1\": c3, \"2\": c4, \"3\": c5})\n        return feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.567563Z","iopub.execute_input":"2025-12-10T20:02:50.567815Z","iopub.status.idle":"2025-12-10T20:02:50.581892Z","shell.execute_reply.started":"2025-12-10T20:02:50.567792Z","shell.execute_reply":"2025-12-10T20:02:50.581036Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.582696Z","iopub.execute_input":"2025-12-10T20:02:50.582935Z","iopub.status.idle":"2025-12-10T20:02:50.597434Z","shell.execute_reply.started":"2025-12-10T20:02:50.582919Z","shell.execute_reply":"2025-12-10T20:02:50.596788Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def evaluate_val_loss(model, loader):\n    model.eval()\n    total = 0.0\n    with torch.no_grad():\n        for images, targets in loader:\n            images  = [img.to(device) for img in images]\n            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n            loss_dict = model(images, targets)\n            loss = sum(loss for loss in loss_dict.values())\n            total += loss.item()\n    return total / max(1, len(loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.599658Z","iopub.execute_input":"2025-12-10T20:02:50.599885Z","iopub.status.idle":"2025-12-10T20:02:50.610419Z","shell.execute_reply.started":"2025-12-10T20:02:50.599870Z","shell.execute_reply":"2025-12-10T20:02:50.609687Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def show_test_predictions_5(model, test_samples, score_thresh=0.5):\n    model.eval()\n    chosen = random.sample(test_samples, min(5, len(test_samples)))\n\n    for idx, sample in enumerate(chosen):\n        print(f\"\\nsample {idx+1}\")\n\n        rgb = cv2.imread(sample[\"rgb\"])\n        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB).astype(np.uint8)\n\n        dR = cv2.imread(sample[\"depth_real\"],  cv2.IMREAD_ANYDEPTH).astype(np.float32)\n        dM = cv2.imread(sample[\"depth_midas\"], cv2.IMREAD_ANYDEPTH).astype(np.float32)\n\n        h0, w0 = rgb.shape[:2]\n\n        scale = min(IMG_SIZE / h0, IMG_SIZE / w0)\n        new_w, new_h = int(w0 * scale), int(h0 * scale)\n\n        rgb_rs = cv2.resize(rgb, (new_w, new_h))\n        dR_rs  = cv2.resize(dR,  (new_w, new_h))\n        dM_rs  = cv2.resize(dM,  (new_w, new_h))\n\n        pad_w = IMG_SIZE - new_w\n        pad_h = IMG_SIZE - new_h\n        pad_left = pad_w // 2\n        pad_top  = pad_h // 2\n\n        rgb_pad = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n        dR_pad  = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.float32)\n        dM_pad  = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.float32)\n\n        rgb_pad[pad_top:pad_top+new_h, pad_left:pad_left+new_w] = rgb_rs\n        dR_pad [pad_top:pad_top+new_h, pad_left:pad_left+new_w] = dR_rs\n        dM_pad [pad_top:pad_top+new_h, pad_left:pad_left+new_w] = dM_rs\n\n        rgb_norm = rgb_pad.astype(np.float32) / 255.0\n        dR_norm  = (dR_pad - DEPTH_MIN) / (DEPTH_MAX - DEPTH_MIN + 1e-6)\n        dM_norm  = (dM_pad - DEPTH_MIN) / (DEPTH_MAX - DEPTH_MIN + 1e-6)\n\n        x = np.concatenate(\n            [rgb_norm, dR_norm[..., None], dM_norm[..., None]],\n            axis=2\n        )\n        x_t = torch.from_numpy(x).permute(2,0,1).unsqueeze(0).float().to(device)\n\n        with torch.no_grad():\n            out = model([x_t[0]])[0]\n\n        boxes  = out[\"boxes\"].cpu().numpy()\n        labels = out[\"labels\"].cpu().numpy()\n        scores = out[\"scores\"].cpu().numpy()\n\n        vis = rgb_pad.copy()\n\n        for box, lbl, sc in zip(boxes, labels, scores):\n            if sc < score_thresh:\n                continue\n            x1,y1,x2,y2 = box.astype(int)\n            cls_id = int(lbl) - 1\n            if cls_id < 0 or cls_id >= len(CLASSES):\n                continue\n            name = CLASSES[cls_id]\n\n            cv2.rectangle(vis, (x1, y1), (x2, y2), (255, 0, 0), 2)\n            cv2.putText(\n                vis,\n                f\"{name} {sc:.2f}\",\n                (x1, max(15, y1 - 5)),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                0.6,\n                (255, 0, 0),\n                2\n            )\n\n        plt.figure(figsize=(7,7))\n        plt.title(f\"Test Prediction {idx+1}\")\n        plt.imshow(vis)\n        plt.axis(\"off\")\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.611165Z","iopub.execute_input":"2025-12-10T20:02:50.611412Z","iopub.status.idle":"2025-12-10T20:02:50.626245Z","shell.execute_reply.started":"2025-12-10T20:02:50.611386Z","shell.execute_reply":"2025-12-10T20:02:50.625706Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def box_iou(box1, box2):\n    x1 = max(float(box1[0]), float(box2[0]))\n    y1 = max(float(box1[1]), float(box2[1]))\n    x2 = min(float(box1[2]), float(box2[2]))\n    y2 = min(float(box1[3]), float(box2[3]))\n\n    inter_w = max(0.0, x2 - x1)\n    inter_h = max(0.0, y2 - y1)\n    inter = inter_w * inter_h\n\n    if inter <= 0.0:\n        return 0.0\n\n    area1 = max(0.0, float(box1[2]) - float(box1[0])) * max(0.0, float(box1[3]) - float(box1[1]))\n    area2 = max(0.0, float(box2[2]) - float(box2[0])) * max(0.0, float(box2[3]) - float(box2[1]))\n    union = area1 + area2 - inter\n    if union <= 0.0:\n        return 0.0\n\n    return inter / union","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.626849Z","iopub.execute_input":"2025-12-10T20:02:50.627026Z","iopub.status.idle":"2025-12-10T20:02:50.645124Z","shell.execute_reply.started":"2025-12-10T20:02:50.627012Z","shell.execute_reply":"2025-12-10T20:02:50.644372Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate_detection(model, data_loader, class_names, device=None,\n                    iou_thresh=0.5, score_thresh=0.5):\n    if device is None:\n        device = next(model.parameters()).device\n\n    model.eval()\n\n    num_classes = len(class_names)\n\n    total_gt = 0 \n    total_pred = 0\n    total_tp = 0 \n\n    iou_sum = 0.0\n    iou_cnt = 0\n\n    per_class_gt = [0] * num_classes\n    per_class_pred = [0] * num_classes\n    per_class_tp = [0] * num_classes\n    per_class_iou_sum = [0.0] * num_classes\n    per_class_iou_cnt = [0] * num_classes\n\n    for images, targets in data_loader:\n        images = [img.to(device) for img in images]\n\n        outputs = model(images)\n\n        for out, tgt in zip(outputs, targets):\n            gt_boxes = tgt[\"boxes\"].cpu().numpy()\n            gt_labels = tgt[\"labels\"].cpu().numpy() \n\n            total_gt += len(gt_boxes)\n            for lbl in gt_labels:\n                if 1 <= lbl <= num_classes:\n                    per_class_gt[lbl - 1] += 1\n\n            if len(gt_boxes) == 0:\n                pred_scores = out[\"scores\"].cpu().numpy()\n                pred_labels = out[\"labels\"].cpu().numpy()\n\n                keep = pred_scores >= score_thresh\n                pred_labels = pred_labels[keep]\n\n                num_pred = len(pred_labels)\n                total_pred += num_pred\n                for lbl in pred_labels:\n                    if 1 <= lbl <= num_classes:\n                        per_class_pred[lbl - 1] += 1\n                continue\n\n            pred_boxes = out[\"boxes\"].cpu().numpy()\n            pred_labels = out[\"labels\"].cpu().numpy()\n            pred_scores = out[\"scores\"].cpu().numpy()\n\n            keep = pred_scores >= score_thresh\n            pred_boxes = pred_boxes[keep]\n            pred_labels = pred_labels[keep]\n            pred_scores = pred_scores[keep]\n\n            total_pred += len(pred_boxes)\n            for lbl in pred_labels:\n                if 1 <= lbl <= num_classes:\n                    per_class_pred[lbl - 1] += 1\n\n            matched_gt = np.zeros(len(gt_boxes), dtype=bool)\n\n            order = np.argsort(-pred_scores)\n            for p_idx in order:\n                p_box = pred_boxes[p_idx]\n                p_lbl = pred_labels[p_idx]\n                if not (1 <= p_lbl <= num_classes):\n                    continue\n\n                best_iou = 0.0\n                best_gt_idx = -1\n\n                for g_idx, (g_box, g_lbl) in enumerate(zip(gt_boxes, gt_labels)):\n                    if matched_gt[g_idx]:\n                        continue\n                    if g_lbl != p_lbl:\n                        continue\n\n                    iou = box_iou(p_box, g_box)\n                    if iou > best_iou:\n                        best_iou = iou\n                        best_gt_idx = g_idx\n\n                if best_gt_idx >= 0 and best_iou >= iou_thresh:\n                    matched_gt[best_gt_idx] = True\n                    total_tp += 1\n\n                    iou_sum += best_iou\n                    iou_cnt += 1\n\n                    c = p_lbl - 1\n                    per_class_tp[c] += 1\n                    per_class_iou_sum[c] += best_iou\n                    per_class_iou_cnt[c] += 1\n                else:\n                    pass\n\n    def safe_div(a, b):\n        return a / b if b > 0 else 0.0\n\n    overall_precision = safe_div(total_tp, total_pred)\n    overall_recall = safe_div(total_tp, total_gt)\n    overall_f1 = safe_div(2 * overall_precision * overall_recall,\n                        overall_precision + overall_recall)\n    overall_iou = safe_div(iou_sum, iou_cnt)\n\n    print(\"Detection metrics: IoU >= {:.2f}, score >= {:.2f}\".format(\n        iou_thresh, score_thresh))\n    print(f\"  GT: {total_gt}, Pred: {total_pred}, TP: {total_tp}\")\n    print(f\"Precision: {overall_precision:.4f}\")\n    print(f\"Recall:    {overall_recall:.4f}\")\n    print(f\"F1-score:  {overall_f1:.4f}\")\n    print(f\"Avg IoU by TP: {overall_iou:.4f}\")\n\n    print(\"\\nMetrics by classes:\")\n    for idx, name in enumerate(class_names):\n        tp = per_class_tp[idx]\n        gt = per_class_gt[idx]\n        pred = per_class_pred[idx]\n        prec = safe_div(tp, pred)\n        rec = safe_div(tp, gt)\n        f1 = safe_div(2 * prec * rec, prec + rec)\n        avg_iou = safe_div(per_class_iou_sum[idx], per_class_iou_cnt[idx])\n\n        print(f\"[{idx+1}] {name}:\")\n        print(f\"  GT: {gt}, Pred: {pred}, TP: {tp}\")\n        print(f\"  Precision: {prec:.4f}\")\n        print(f\"  Recall:    {rec:.4f}\")\n        print(f\"  F1-score:  {f1:.4f}\")\n        print(f\"  Avg IoU:   {avg_iou:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.645901Z","iopub.execute_input":"2025-12-10T20:02:50.646196Z","iopub.status.idle":"2025-12-10T20:02:50.661649Z","shell.execute_reply.started":"2025-12-10T20:02:50.646180Z","shell.execute_reply":"2025-12-10T20:02:50.661087Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\nwith open(CLASSES_PATH) as f:\n    CLASSES = [x.strip() for x in f.readlines() if x.strip()]\n\nNUM_CLASSES = len(CLASSES) + 1\nprint(\"Classes:\", CLASSES)\n\nsamples = collect_samples()\nprint(\"Samples collected len:\", len(samples))\n\nDEPTH_MIN, DEPTH_MAX = compute_global_min_max(samples)\nprint(f\"DEPTH RANGE: min={DEPTH_MIN}, max={DEPTH_MAX}\")\n\nrandom.shuffle(samples)\n\nn_total = len(samples)\nn_train = int(0.75 * n_total)\n\ntrain_samples = samples[:n_train]\ntest_samples  = samples[n_train:]\n\nprint(f\"Train: {len(train_samples)}, Test: {len(test_samples)}\")\n\ntrain_loader = DataLoader(\n    RGBRealMiDaSDataset(train_samples),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    collate_fn=collate_fn\n)\n\ntest_loader = DataLoader(\n    RGBRealMiDaSDataset(test_samples),\n    batch_size=1,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n\nbackbone = RGBRM_Backbone().to(device)\n\nanchor_generator = AnchorGenerator(\n    sizes=((32,), (64,), (128,), (256,), (512,)),\n    aspect_ratios=((0.5, 1.0, 2.0),) * 5\n)\n\nroi_pooler = MultiScaleRoIAlign(\n    featmap_names=[\"0\", \"1\", \"2\", \"3\", \"pool\"],\n    output_size=7,\n    sampling_ratio=2\n)\n\nmodel = FasterRCNN(\n    backbone,\n    num_classes=NUM_CLASSES,\n    rpn_anchor_generator=anchor_generator,\n    box_roi_pool=roi_pooler,\n    image_mean=[0.5] * 5,\n    image_std=[0.25] * 5\n).to(device)\n\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(\n    params,\n    lr=LR,\n    momentum=0.9,\n    weight_decay=1e-4\n)\n\nbest_val_loss = float(\"inf\")\n\nprint(\"\\ntrain\")\n\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    total_loss = 0.0\n    n_batches = 0\n\n    for images, targets in train_loader:\n        images = [img.to(device) for img in images]\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n        losses = sum(loss for loss in loss_dict.values())\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        total_loss += losses.item()\n        n_batches += 1\n\n    print(f\"Epoch {epoch}/{EPOCHS} | train_loss = {total_loss / n_batches:.4f}\")\n\ntorch.save(model.state_dict(), \"rgbdd_fasterrcnn_gating.pth\")\nprint(\"Model saved: rgbdd_fasterrcnn_gating.pth\")\n\nshow_test_predictions_5(model, test_samples, score_thresh=0.75)\n\nevaluate_detection(model, test_loader, CLASSES, device=device, iou_thresh=0.75, score_thresh=0.75)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T20:02:50.662563Z","iopub.execute_input":"2025-12-10T20:02:50.662768Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nClasses: ['bottle', 'box', 'cola', 'container', 'cube', 'duck', 'pods', 'scissors', 'sphere', 'tape', 'tor']\nSamples collected len: 3117\nDEPTH RANGE: min=0.0, max=65535.0\nTrain: 2337, Test: 780\n\ntrain\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}